"""
RAG æœåŠ¡ï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
å®ç°å‘é‡æ£€ç´¢ + ä¸Šä¸‹æ–‡å¢å¼º + ç”Ÿæˆå›ç­”çš„å®Œæ•´æµç¨‹
"""

from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session

from app.services.vector_service import vector_service
from app.services.ai_service import ai_service
from app.models import Document, KnowledgeBase


class RAGService:
    """RAG æœåŠ¡ç±»"""

    def __init__(self, db: Session):
        """åˆå§‹åŒ–æœåŠ¡"""
        self.db = db
        self.vector_service = vector_service
        self.ai_service = ai_service

    def _extract_keywords(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            List[str]: å…³é”®è¯åˆ—è¡¨
        """
        # ç®€å•å®ç°ï¼šæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²
        import re

        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        query_clean = re.sub(r'[^\w\s]', ' ', query)
        # åˆ†å‰²å¹¶è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        keywords = [k for k in query_clean.split() if len(k) > 1]

        return keywords[:5]  # è¿”å›å‰ 5 ä¸ªå…³é”®è¯

    async def _vector_search(
        self,
        query: str,
        knowledge_base_id: Optional[int] = None,
        top_k: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        å‘é‡æ£€ç´¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            knowledge_base_id: çŸ¥è¯†åº“ IDï¼ˆå¯é€‰ï¼‰
            top_k: è¿”å›å‰ K ä¸ªç»“æœ

        Returns:
            List[Dict]: æ£€ç´¢ç»“æœ
        """
        return await self.vector_service.search(
            query=query,
            knowledge_base_id=knowledge_base_id,
            top_k=top_k,
        )

    def _build_context(
        self,
        search_results: List[Dict[str, Any]],
        max_context_length: int = 3000,
    ) -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡

        Args:
            search_results: å‘é‡æœç´¢ç»“æœ
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰

        Returns:
            str: æ„å»ºçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not search_results:
            return ""

        context_parts = []
        current_length = 0

        for idx, result in enumerate(search_results):
            text = result["text"]
            score = result["score"]
            document_id = result["document_id"]

            # è·å–æ–‡æ¡£æ ‡é¢˜
            document = self.db.query(Document).filter(Document.id == document_id).first()
            title = document.title if document else "æœªçŸ¥æ–‡æ¡£"

            # æ„å»ºä¸Šä¸‹æ–‡ç‰‡æ®µ
            context_part = f"\nã€æ¥æº {idx + 1}ã€‘{title} (ç›¸ä¼¼åº¦: {score:.3f})\n{text}\n"

            # æ£€æŸ¥é•¿åº¦
            if current_length + len(context_part) > max_context_length:
                break

            context_parts.append(context_part)
            current_length += len(context_part)

        return "".join(context_parts)

    async def _generate_answer(
        self,
        query: str,
        context: str,
        system_prompt: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        å¢å¼ºç”Ÿæˆ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            Dict: ç”Ÿæˆç»“æœ
        """
        # é»˜è®¤ç³»ç»Ÿæç¤ºè¯
        if system_prompt is None:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿åŸºäºæä¾›çš„çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. ä¼˜å…ˆä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®å‘ŠçŸ¥ç”¨æˆ·
3. å¼•ç”¨å…·ä½“çš„æ¥æºï¼ˆæ–‡æ¡£æ ‡é¢˜ï¼‰
4. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰é€»è¾‘
5. å¦‚æœé—®é¢˜æ¶‰åŠå¤šä¸ªæ–¹é¢ï¼Œè¯·åˆ†ç‚¹å›ç­”"""

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = f"""å‚è€ƒä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{query}

è¯·æ ¹æ®å‚è€ƒä¿¡æ¯å›ç­”ä¸Šè¿°é—®é¢˜ã€‚"""

        # è°ƒç”¨ AI ç”Ÿæˆ
        ai_response = await self.ai_service.chat(
            messages=[{"role": "user", "content": user_message}],
            system_prompt=system_prompt,
            temperature=0.7,
        )

        return ai_response

    async def query(
        self,
        question: str,
        knowledge_base_id: Optional[int] = None,
        top_k: Optional[int] = None,
        system_prompt: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹

        Args:
            question: ç”¨æˆ·é—®é¢˜
            knowledge_base_id: çŸ¥è¯†åº“ IDï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™æœç´¢å…¨éƒ¨ï¼‰
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„å‰ K ä¸ªæ–‡æ¡£ç‰‡æ®µ
            system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯

        Returns:
            Dict: RAG æŸ¥è¯¢ç»“æœï¼ŒåŒ…å«ï¼š
                - success: æ˜¯å¦æˆåŠŸ
                - answer: ç”Ÿæˆçš„å›ç­”
                - sources: å¼•ç”¨çš„æ¥æºæ–‡æ¡£åˆ—è¡¨
                - context: ä½¿ç”¨çš„ä¸Šä¸‹æ–‡
                - tokens: Token æ¶ˆè€—
                - cost: æˆæœ¬
        """
        try:
            # Step 1: æå–å…³é”®è¯ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
            keywords = self._extract_keywords(question)
            print(f"ğŸ” æå–çš„å…³é”®è¯: {keywords}")

            # Step 2: å‘é‡æ£€ç´¢
            print(f"ğŸ” å¼€å§‹å‘é‡æ£€ç´¢...")
            search_results = await self._vector_search(
                query=question,
                knowledge_base_id=knowledge_base_id,
                top_k=top_k,
            )

            print(f"ğŸ” æ£€ç´¢åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

            if not search_results:
                # å¦‚æœæ²¡æœ‰æ£€ç´¢ç»“æœï¼Œç›´æ¥ç”Ÿæˆå›ç­”ï¼ˆä¸ä½¿ç”¨ RAGï¼‰
                print("âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œç›´æ¥ç”Ÿæˆå›ç­”")
                ai_response = await self.ai_service.chat(
                    messages=[{"role": "user", "content": question}],
                    system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚",
                )

                return {
                    "success": ai_response["success"],
                    "answer": ai_response["content"] if ai_response["success"] else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚",
                    "sources": [],
                    "context": "",
                    "tokens": ai_response.get("tokens"),
                    "cost": ai_response.get("cost"),
                    "rag_enabled": False,
                }

            # Step 3: æ„å»ºä¸Šä¸‹æ–‡
            print("ğŸ” æ„å»ºä¸Šä¸‹æ–‡...")
            context = self._build_context(search_results)

            # Step 4: å¢å¼ºç”Ÿæˆ
            print("ğŸ” å¢å¼ºç”Ÿæˆä¸­...")
            ai_response = await self._generate_answer(
                query=question,
                context=context,
                system_prompt=system_prompt,
            )

            # Step 5: æ„å»ºè¿”å›ç»“æœ
            if ai_response["success"]:
                # æå–æ¥æºä¿¡æ¯
                sources = []
                seen_docs = set()

                for result in search_results:
                    doc_id = result["document_id"]
                    if doc_id not in seen_docs:
                        document = self.db.query(Document).filter(Document.id == doc_id).first()
                        if document:
                            sources.append({
                                "document_id": doc_id,
                                "title": document.title,
                                "score": result["score"],
                            })
                            seen_docs.add(doc_id)

                return {
                    "success": True,
                    "answer": ai_response["content"],
                    "sources": sources,
                    "context": context,
                    "tokens": ai_response["tokens"],
                    "cost": ai_response["cost"],
                    "rag_enabled": True,
                    "search_results_count": len(search_results),
                }
            else:
                return {
                    "success": False,
                    "error": ai_response["error"],
                    "answer": "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚",
                }

        except Exception as e:
            print(f"âŒ RAG æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "answer": "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚",
            }

    async def index_document(
        self,
        knowledge_base_id: int,
        document_id: int,
        text: str,
    ) -> Dict[str, Any]:
        """
        ç´¢å¼•æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“

        Args:
            knowledge_base_id: çŸ¥è¯†åº“ ID
            document_id: æ–‡æ¡£ ID
            text: æ–‡æ¡£å†…å®¹

        Returns:
            Dict: ç´¢å¼•ç»“æœ
        """
        return await self.vector_service.add_document_chunks(
            knowledge_base_id=knowledge_base_id,
            document_id=document_id,
            text=text,
        )

    async def delete_document_index(self, document_id: int) -> bool:
        """
        åˆ é™¤æ–‡æ¡£çš„å‘é‡ç´¢å¼•

        Args:
            document_id: æ–‡æ¡£ ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return await self.vector_service.delete_document_chunks(document_id)

    async def delete_knowledge_base_index(self, knowledge_base_id: int) -> bool:
        """
        åˆ é™¤çŸ¥è¯†åº“çš„å‘é‡ç´¢å¼•

        Args:
            knowledge_base_id: çŸ¥è¯†åº“ ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return await self.vector_service.delete_knowledge_base_chunks(knowledge_base_id)


# å·¥å‚å‡½æ•°ï¼šåˆ›å»º RAG æœåŠ¡å®ä¾‹
def create_rag_service(db: Session) -> RAGService:
    """åˆ›å»º RAG æœåŠ¡å®ä¾‹"""
    return RAGService(db)
