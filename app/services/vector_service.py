"""
å‘é‡æœåŠ¡ - åŸºäº Qdrant
å¤„ç† Qdrant å‘é‡æ•°æ®åº“å’Œæ–‡æ¡£å‘é‡åŒ–
"""

from typing import List, Dict, Any, Optional
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    Filter,
    FieldCondition,
    MatchValue,
    OptimizersConfigDiff,
)
from qdrant_client.http.exceptions import UnexpectedResponse
from zhipuai import ZhipuAI
import redis
import json
import hashlib
import uuid
from datetime import datetime

from app.core.config import settings
from app.core.logger import logger


class VectorService:
    """å‘é‡æœåŠ¡ç±» - Qdrant å®ç°"""

    def __init__(self):
        """åˆå§‹åŒ–å‘é‡æœåŠ¡"""
        # Qdrant è¿æ¥é…ç½®
        self.qdrant_host = settings.QDRANT_HOST
        self.qdrant_port = settings.QDRANT_PORT
        self.qdrant_api_key = settings.QDRANT_API_KEY if settings.QDRANT_API_KEY else None
        self.collection_name = settings.QDRANT_COLLECTION_NAME
        self.vector_size = settings.QDRANT_VECTOR_SIZE
        self.distance = Distance.COSINE if settings.QDRANT_DISTANCE == "Cosine" else Distance.EUCLID

        # Zhipu AI Embedding API
        self.embedding_client = ZhipuAI(api_key=settings.ZHIPUAI_API_KEY)

        # Redis ç¼“å­˜
        try:
            self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            logger.info("âœ… Redis ç¼“å­˜å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis è¿æ¥å¤±è´¥ï¼Œå°†ç¦ç”¨ç¼“å­˜: {e}")
            self.redis_client = None

        # è¿æ¥ Qdrant
        self._connect_qdrant()

        # ç¡®ä¿é›†åˆå­˜åœ¨
        self._ensure_collection()

    def _connect_qdrant(self):
        """è¿æ¥åˆ° Qdrant"""
        try:
            self.client = QdrantClient(
                host=self.qdrant_host,
                port=self.qdrant_port,
                api_key=self.qdrant_api_key,
            )
            logger.info(f"âœ… å·²è¿æ¥åˆ° Qdrant: {self.qdrant_host}:{self.qdrant_port}")
        except Exception as e:
            logger.error(f"âŒ è¿æ¥ Qdrant å¤±è´¥: {e}")
            raise

    def _ensure_collection(self):
        """ç¡®ä¿å‘é‡é›†åˆå­˜åœ¨"""
        try:
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            collections = self.client.get_collections().collections
            collection_names = [c.name for c in collections]

            if self.collection_name not in collection_names:
                # åˆ›å»ºé›†åˆ
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=self.vector_size,
                        distance=self.distance,
                    ),
                    optimizers_config=OptimizersConfigDiff(
                        indexing_threshold=10000,  # 10000 ä¸ªç‚¹åå¼€å§‹ç´¢å¼•
                    ),
                )
                logger.info(f"âœ… åˆ›å»º Qdrant é›†åˆ: {self.collection_name}")
            else:
                logger.info(f"âœ… Qdrant é›†åˆå·²å­˜åœ¨: {self.collection_name}")

        except Exception as e:
            logger.error(f"âŒ ç¡®ä¿ Qdrant é›†åˆå¤±è´¥: {e}")
            raise

    async def get_embedding(self, text: str) -> List[float]:
        """
        è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            List[float]: å‘é‡è¡¨ç¤º
        """
        if not text or not text.strip():
            raise ValueError("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"embedding:{hashlib.md5(text.encode()).hexdigest()}"

        # å°è¯•ä»ç¼“å­˜è·å–
        if settings.RAG_ENABLE_CACHE and self.redis_client:
            try:
                cached = self.redis_client.get(cache_key)
                if cached:
                    logger.debug(f"ğŸ¯ ä»ç¼“å­˜è·å–å‘é‡: {cache_key[:20]}...")
                    return json.loads(cached)
            except Exception as e:
                logger.warning(f"âš ï¸ Redis ç¼“å­˜è¯»å–å¤±è´¥: {e}")

        try:
            # è°ƒç”¨ Zhipu AI Embedding API
            response = self.embedding_client.embeddings.create(
                model="embedding-2",
                input=text,
            )

            embedding = response.data[0].embedding

            # ç¼“å­˜ç»“æœ
            if settings.RAG_ENABLE_CACHE and self.redis_client:
                try:
                    self.redis_client.setex(
                        cache_key,
                        settings.RAG_REDIS_CACHE_TTL,
                        json.dumps(embedding),
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ Redis ç¼“å­˜å†™å…¥å¤±è´¥: {e}")

            return embedding

        except Exception as e:
            logger.error(f"âŒ è·å– Embedding å¤±è´¥: {e}")
            raise

    def chunk_text(
        self,
        text: str,
        chunk_size: Optional[int] = None,
        overlap: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        å°†æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªå—ï¼ˆæ™ºèƒ½åˆ†å—ï¼‰

        Args:
            text: è¾“å…¥æ–‡æœ¬
            chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            overlap: é‡å å¤§å°

        Returns:
            List[Dict]: æ–‡æœ¬å—åˆ—è¡¨ï¼ŒåŒ…å«æ–‡æœ¬å’Œå…ƒæ•°æ®
        """
        if not text or not text.strip():
            return []

        chunk_size = chunk_size or settings.RAG_CHUNK_SIZE
        overlap = overlap or settings.RAG_CHUNK_OVERLAP

        chunks = []
        lines = text.split('\n')
        current_chunk = []
        current_length = 0
        chunk_index = 0

        for line in lines:
            line_length = len(line)

            # å¦‚æœå½“å‰è¡Œè¶…è¿‡å—å¤§å°ï¼Œéœ€è¦æ‹†åˆ†
            if line_length > chunk_size:
                # å…ˆä¿å­˜å½“å‰å—
                if current_chunk:
                    chunk_text = '\n'.join(current_chunk)
                    chunks.append({
                        'text': chunk_text,
                        'index': chunk_index,
                        'length': len(chunk_text),
                    })
                    chunk_index += 1
                    current_chunk = []
                    current_length = 0

                # æ‹†åˆ†é•¿è¡Œ
                for i in range(0, line_length, chunk_size - overlap):
                    chunk_text = line[i:i + chunk_size]
                    chunks.append({
                        'text': chunk_text,
                        'index': chunk_index,
                        'length': len(chunk_text),
                    })
                    chunk_index += 1
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°å—
                if current_length + line_length + 1 > chunk_size and current_chunk:
                    # ä¿å­˜å½“å‰å—
                    chunk_text = '\n'.join(current_chunk)
                    chunks.append({
                        'text': chunk_text,
                        'index': chunk_index,
                        'length': len(chunk_text),
                    })
                    chunk_index += 1

                    # ä¿ç•™éƒ¨åˆ†é‡å å†…å®¹
                    if overlap > 0 and len(current_chunk) > 1:
                        overlap_text = '\n'.join(current_chunk[-2:])  # ä¿ç•™æœ€å 2 è¡Œ
                        current_chunk = [overlap_text]
                        current_length = len(overlap_text)
                    else:
                        current_chunk = []
                        current_length = 0

                # æ·»åŠ è¡Œåˆ°å½“å‰å—
                current_chunk.append(line)
                current_length += line_length + 1  # +1 for newline

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunk_text = '\n'.join(current_chunk)
            chunks.append({
                'text': chunk_text,
                'index': chunk_index,
                'length': len(chunk_text),
            })

        logger.info(f"ğŸ“„ æ–‡æœ¬åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
        return chunks

    async def add_document_chunks(
        self,
        knowledge_base_id: int,
        document_id: int,
        text: str,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        æ·»åŠ æ–‡æ¡£çš„æ–‡æœ¬å—åˆ°å‘é‡æ•°æ®åº“

        Args:
            knowledge_base_id: çŸ¥è¯†åº“ ID
            document_id: æ–‡æ¡£ ID
            text: æ–‡æ¡£å†…å®¹
            metadata: é¢å¤–å…ƒæ•°æ®

        Returns:
            Dict: åŒ…å«æ·»åŠ çš„å—æ•°é‡ç­‰ä¿¡æ¯
        """
        try:
            # åˆ†å‰²æ–‡æœ¬
            chunks = self.chunk_text(text)

            if not chunks:
                return {
                    "success": False,
                    "error": "æ–‡æœ¬ä¸ºç©ºæˆ–æ— æ³•åˆ†å‰²",
                }

            # ä¸ºæ¯ä¸ªå—ç”Ÿæˆå‘é‡å’Œç‚¹
            points = []
            for chunk in chunks:
                # ç”Ÿæˆå‘é‡
                embedding = await self.get_embedding(chunk['text'])

                # åˆ›å»ºå”¯ä¸€ ID
                point_id = str(uuid.uuid4())

                # å‡†å¤‡å…ƒæ•°æ®
                point_metadata = {
                    "knowledge_base_id": knowledge_base_id,
                    "document_id": document_id,
                    "chunk_index": chunk['index'],
                    "text": chunk['text'],
                    "length": chunk['length'],
                    "created_at": datetime.utcnow().isoformat(),
                    **(metadata or {}),
                }

                # åˆ›å»ºç‚¹ç»“æ„
                point = PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload=point_metadata,
                )
                points.append(point)

            # æ‰¹é‡æ’å…¥åˆ° Qdrant
            self.client.upsert(
                collection_name=self.collection_name,
                points=points,
            )

            logger.info(f"âœ… æ·»åŠ äº† {len(chunks)} ä¸ªæ–‡æ¡£å—åˆ° Qdrant")

            return {
                "success": True,
                "chunk_count": len(chunks),
                "point_ids": [p.id for p in points],
            }

        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å—å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
            }

    async def search(
        self,
        query: str,
        knowledge_base_id: Optional[int] = None,
        top_k: Optional[int] = None,
        score_threshold: Optional[float] = None,
    ) -> List[Dict[str, Any]]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            knowledge_base_id: çŸ¥è¯†åº“ IDï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ï¼‰
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„å‰ K ä¸ªç»“æœ
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰

        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨
        """
        if top_k is None:
            top_k = settings.RAG_TOP_K

        try:
            # è·å–æŸ¥è¯¢å‘é‡
            query_embedding = await self.get_embedding(query)

            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            query_filter = None
            if knowledge_base_id is not None:
                query_filter = Filter(
                    must=[
                        FieldCondition(
                            key="knowledge_base_id",
                            match=MatchValue(value=knowledge_base_id),
                        )
                    ]
                )

            # æ‰§è¡Œæœç´¢
            search_result = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=top_k,
                query_filter=query_filter,
                score_threshold=score_threshold,
            )

            # è§£æç»“æœ
            results = []
            for hit in search_result:
                results.append({
                    "point_id": hit.id,
                    "document_id": hit.payload.get("document_id"),
                    "chunk_index": hit.payload.get("chunk_index"),
                    "text": hit.payload.get("text"),
                    "score": hit.score,
                    "metadata": hit.payload,
                })

            logger.info(f"ğŸ” å‘é‡æœç´¢å®Œæˆ: {len(results)} ä¸ªç»“æœ")
            return results

        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            return []

    async def delete_document_chunks(self, document_id: int) -> bool:
        """
        åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰æ–‡æœ¬å—

        Args:
            document_id: æ–‡æ¡£ ID

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            # ä½¿ç”¨è¿‡æ»¤æ¡ä»¶åˆ é™¤
            self.client.delete(
                collection_name=self.collection_name,
                points_selector=Filter(
                    must=[
                        FieldCondition(
                            key="document_id",
                            match=MatchValue(value=document_id),
                        )
                    ]
                ),
            )

            logger.info(f"âœ… åˆ é™¤äº†æ–‡æ¡£ {document_id} çš„æ‰€æœ‰æ–‡æœ¬å—")
            return True

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ–‡æ¡£å—å¤±è´¥: {e}")
            return False

    async def delete_knowledge_base_chunks(self, knowledge_base_id: int) -> bool:
        """
        åˆ é™¤çŸ¥è¯†åº“çš„æ‰€æœ‰æ–‡æœ¬å—

        Args:
            knowledge_base_id: çŸ¥è¯†åº“ ID

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            # ä½¿ç”¨è¿‡æ»¤æ¡ä»¶åˆ é™¤
            self.client.delete(
                collection_name=self.collection_name,
                points_selector=Filter(
                    must=[
                        FieldCondition(
                            key="knowledge_base_id",
                            match=MatchValue(value=knowledge_base_id),
                        )
                    ]
                ),
            )

            logger.info(f"âœ… åˆ é™¤äº†çŸ¥è¯†åº“ {knowledge_base_id} çš„æ‰€æœ‰æ–‡æœ¬å—")
            return True

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤çŸ¥è¯†åº“å—å¤±è´¥: {e}")
            return False

    async def get_collection_stats(self) -> Dict[str, Any]:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            collection_info = self.client.get_collection(self.collection_name)
            return {
                "points_count": collection_info.points_count,
                "vectors_count": collection_info.vectors_count,
                "status": collection_info.status.value,
                "optimizer_status": collection_info.optimizer_status,
            }
        except Exception as e:
            logger.error(f"âŒ è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


# åˆ›å»ºå…¨å±€å‘é‡æœåŠ¡å®ä¾‹
vector_service = VectorService()
